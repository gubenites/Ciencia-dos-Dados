{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-5cf9506c910a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auth.pass'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @gubenites99\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'game of thrones'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-382-910742af87dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Cria um objeto para a captura\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Inicia a captura, para mais detalhes: ver a documentação do tweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atribuí nota 10 ao episódio 7x4 - the spoils o...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manoo game of thrones é bom demais</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>domingo sem game of thrones não é domingo</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @snowlives: game of thrones não é indicada ...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @jenlxaw: \"ganhadores não esqueçam de agrad...</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Relevancia\n",
       "0  atribuí nota 10 ao episódio 7x4 - the spoils o...        Não\n",
       "1                 manoo game of thrones é bom demais        Sim\n",
       "2          domingo sem game of thrones não é domingo        Sim\n",
       "3  rt @snowlives: game of thrones não é indicada ...        Não\n",
       "4  rt @jenlxaw: \"ganhadores não esqueçam de agrad...        Não"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import tweepy\n",
    "from random import shuffle\n",
    "import sys\n",
    "import mpmath\n",
    "\n",
    "\n",
    "exl=pd.ExcelFile(\"game of thrones.xlsx\")\n",
    "exl.sheet_names\n",
    "[u'Treinamento', u'Teste']\n",
    "twits = exl.parse(\"Treinamento\")\n",
    "twits2 = exl.parse(\"Teste\")\n",
    "\n",
    "twits2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     opovoonline sem game of thrones disputa pelo ...\n",
       "1    vou começar ver 5 temporada de game of thrones...\n",
       "2    gostei de um vídeo youtube httpst.cox86fitrqwz...\n",
       "3    game of thrones não estar emmy eu tô bolada #e...\n",
       "4     emmys sem game of thrones não emmys pronto falei\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twits['Treinamento']=twits['Treinamento'].str.replace(':','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(',','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(\"'\",'')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('-','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('\"','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(')','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('(','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' é ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' a ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' o ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' e ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('rt','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' os ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' as ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' ou ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('  ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' que ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' nas ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' na ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' no ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace(' nos ',' ')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('?','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('/','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('@','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('!','')\n",
    "twits['Treinamento']=twits['Treinamento'].str.replace('|','')\n",
    "twits['Treinamento'] = twits['Treinamento'].str.lower()\n",
    "\n",
    "twits.Treinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    atribuí nota 10 ao episódio 7x4 the spoils of ...\n",
       "1                     manoo game of thrones bom demais\n",
       "2              domingo sem game of thrones não domingo\n",
       "3     snowlives game of thrones não indicada mesmo ...\n",
       "4     jenlxaw ganhadores não esqueçam de agradecer ...\n",
       "Name: Teste, dtype: object"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twits2['Teste']=twits2['Teste'].str.replace(':','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(',','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(\"'\",'')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('-','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('\"','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(')','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('(','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' é ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' a ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' o ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' e ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('rt','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' os ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' as ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' ou ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('  ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' que ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' nas ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' na ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' no ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace(' nos ',' ')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('?','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('/','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('@','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('!','')\n",
    "twits2['Teste']=twits2['Teste'].str.replace('|','')\n",
    "twits2['Teste'] = twits2['Teste'].str.lower()\n",
    "\n",
    "twits2.Teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = []\n",
    "naorelevante = []\n",
    "naorelevante_semrepetiçao = []\n",
    "relevante_semrepetiçao = []\n",
    "all = []\n",
    "all_semrepetiçao = []\n",
    "\n",
    "\n",
    "for i in range(len(twits)): \n",
    "    all+=(list(twits[\"Treinamento\"][i].split()))\n",
    "all_semrepetiçao=(list(set(all)))\n",
    "\n",
    "for i in range(len(twits)):\n",
    "    if twits[\"Relevancia\"][i]==\"Sim\":\n",
    "        relevante+=(list(twits[\"Treinamento\"][i].split()))\n",
    "\n",
    "    if twits[\"Relevancia\"][i]==\"Não\":\n",
    "        naorelevante+=(list(twits[\"Treinamento\"][i].split()))\n",
    "\n",
    "naorelevante_semrepetiçao=list(set(naorelevante))\n",
    "relevante_semrepetiçao=list(set(relevante))\n",
    "\n",
    "\n",
    "numerogeralsemrepetições=len(all_semrepetiçao)\n",
    "relevantecontagem=len(relevante)\n",
    "naorelevantecontagem=len(naorelevante)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quantidade de palavras relevantes\n",
    "Quantidadeprelevante={}\n",
    "Quantidadepnaorelevante={}\n",
    "for i in range(len(relevante)):\n",
    "    if relevante[i] in Quantidadeprelevante:\n",
    "        Quantidadeprelevante[relevante[i]]=Quantidadeprelevante[relevante[i]]+1\n",
    "    else:\n",
    "        Quantidadeprelevante[relevante[i]]=1\n",
    "#Quantidade de palavras não relevantes       \n",
    "for i in range(len(naorelevante)):\n",
    "    if naorelevante[i] in Quantidadepnaorelevante:\n",
    "        Quantidadepnaorelevante[naorelevante[i]]=Quantidadepnaorelevante[naorelevante[i]]+1\n",
    "    else:\n",
    "        Quantidadepnaorelevante[naorelevante[i]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Calculando probabilidade de cada palavra\n",
    "probrelevantepalavra={}\n",
    "probnaorelevantepalavra={}\n",
    "for i in Quantidadeprelevante:\n",
    "    probrelevantepalavra[i]=(Quantidadeprelevante[i]+1)/(numerogeralsemrepetições+relevantecontagem)\n",
    "for i in Quantidadepnaorelevante:\n",
    "    probnaorelevantepalavra[i]=(Quantidadepnaorelevante[i]+1)/(numerogeralsemrepetições+naorelevantecontagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "frasesteste=[]\n",
    "listarelevancia=[]\n",
    "listavaloresfrasesRelevantes=[]\n",
    "listavaloresfrasesNaorelevantes=[]\n",
    "contadorrelvante=1\n",
    "contadornaorelvante=1\n",
    "for i in twits2['Teste']:\n",
    "    a=i.split()\n",
    "    frasesteste.append(a)\n",
    "#Relevancia\n",
    "for i in frasesteste:\n",
    "    for h in i:\n",
    "        if h in probrelevantepalavra:\n",
    "            contadorrelvante=contadorrelvante*probrelevantepalavra[h]\n",
    "        else:\n",
    "            contadorrelvante=contadorrelvante*(1)/(numerogeralsemrepetições+relevantecontagem)\n",
    "    contadorrelvante=mpmath.mpf(contadorrelvante)\n",
    "    listavaloresfrasesRelevantes.append(contadorrelvante)\n",
    "    contadorrelvante=1\n",
    "#Nao Relevante\n",
    "for i in frasesteste:\n",
    "    for h in i:\n",
    "        if h in probnaorelevantepalavra:\n",
    "            contadornaorelvante=contadornaorelvante*probnaorelevantepalavra[h]     \n",
    "        else:\n",
    "            contadorrelvante=contadorrelvante*(1)/(numerogeralsemrepetições+naorelevantecontagem)\n",
    "    contadornaorelvante=mpmath.mpf(contadornaorelvante)\n",
    "    listavaloresfrasesNaorelevantes.append(contadornaorelvante)\n",
    "    contadornaorelvante=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListaRelevanciaTeste=[]\n",
    "for i in range(len(listavaloresfrasesRelevantes)):\n",
    "    if listavaloresfrasesRelevantes[i]>listavaloresfrasesNaorelevantes[i]:\n",
    "        ListaRelevanciaTeste.append('Sim')\n",
    "    if listavaloresfrasesRelevantes[i]<listavaloresfrasesNaorelevantes[i]:\n",
    "        ListaRelevanciaTeste.append('Não')\n",
    "    if listavaloresfrasesRelevantes[i]==listavaloresfrasesNaorelevantes[i]:\n",
    "        ListaRelevanciaTeste.append('Neutro')\n",
    "twits2[\"Relevancia Teste\"] = pd.Series(ListaRelevanciaTeste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante          158\n",
       "Falso Irrelevante     37\n",
       "Falso Relevante        3\n",
       "Relevante              2\n",
       "Name: Resultados Finais, dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Final=[]\n",
    "\n",
    "for i in range(len(ListaRelevanciaTeste)):\n",
    "    if twits2[\"Relevancia\"][i] == \"Sim\"  and twits2[\"Relevancia Teste\"][i] == \"Sim\":\n",
    "        Final.append(\"Relevante\")\n",
    "        \n",
    "    if twits2[\"Relevancia\"][i] == \"Não\"  and twits2[\"Relevancia Teste\"][i] == \"Sim\":\n",
    "        Final.append(\"Falso Relevante\")\n",
    "        \n",
    "    if twits2[\"Relevancia\"][i] == \"Não\"  and twits2[\"Relevancia Teste\"][i] == \"Não\":\n",
    "        Final.append(\"Irrelevante\")\n",
    "        \n",
    "    if twits2[\"Relevancia\"][i] == \"Sim\" and twits2[\"Relevancia Teste\"][i] ==  \"Não\":\n",
    "        Final.append(\"Falso Irrelevante\")\n",
    "        \n",
    "twits2[\"Resultados Finais\"] = pd.Series(Final) \n",
    "\n",
    "twits2[\"Resultados Finais\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fizemos um algorítimo para selecionar informações separar informações relevantes de irrelevantes vindas de publicações da plataforma Twiter. Para isso tinhamos que escolher um produto especifico e devido a nova temporada de Game of Thrones estar dominando a internet ultimamente fizemos nossa escolha. Como objetivo escolhemos saber o que as pessoas acham da série sendo comentários positivos e negativos e todos os outras coisas fora isso foram filtradas como informações não relevantes.\n",
    "\n",
    "Por meio de uma amostra de treinamento do classificador e da aplicação do Teorema de Bayes conseguimos criar nosso Classificador de Bayes. Com esse classificador conseguimos rodar uma amostra de teste sobre a série e assim comparar os resultados com a amostra de treinamento.\n",
    "\n",
    "No entanto os resultados não foram exatamente o que esperávamos,o classificador retornou apenas 5 mensagens como relevantes sendo dessas 3 eram falsas Relevantes e tivemos 37 mensagens consideras falsas Irrelevantes das 200 mensagens da amostra.Ou seja que da amostra Teste consideramos 39 mensagens como relevantes que o classificador deu como irrelevantes e 3 que consideramos com irrelevantes e o classificador deu como relevantes.\n",
    "\n",
    "Isso se deu provavelmente por 2 fatores principais sendo um deles a surpreendente falta de mensagens de relevantes na nossa base de treinamento fazendo com que utilizaremos mais vezes o método de  Laplace smoothing deixando assim uma grande imprecisão nos resultados e o outro seria por causa de frases sarcasticas e de dupla negação as quais o algorítimo não entende assim provocando uma imprecisão ainda maior.\n",
    "\n",
    "Para melhorar o nosso projeto primeiramente poderíamos aumentar drasticamente nossa base de Treinamento fazendo como que cada vez menos tenham palavras que não estão arquivadas.Com uma amostra maior é possível também em vez de contar palavras soltas, fazer a contagem com pedaços de frases tirando a subjetividade de palavras soltas e colocando mais contexto na classificação. Os criadores da série deveriam continuar financiando o nosso projeto para que assim eles saibam o que o público pensa de seu produto e assim para deixar o seu produto mais parecido com o gosto do seus fãs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
